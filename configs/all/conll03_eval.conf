[1]
tokenizer_path = bert-base-cased
train_path = data/datasets/conll03/conll03_train.json
eval_path = data/datasets/conll03/conll03_test.json
types_path = data/datasets/conll03/conll03_types.json
eval_batch_size = 12
encoding_size = 100
neg_entity_count = 100
neg_relation_count = 100
rel_filter_threshold = 0.4
size_embedding = 25
prop_drop = 0.2
max_span_size = 10
store_examples = true
sampling_processes = 4
sampling_limit = 100
max_pairs = 1000
timestamp_given = true